{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"functions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datastore import DataStore\n",
    "from searchgrid import SearchGrid\n",
    "from crossvalidate import CrossValidate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sampleddatastore import SampledDataStore as sds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load object for CrossValidation\n",
    "crossvalidate = CrossValidate()\n",
    "\n",
    "#Load object for GridSearchCV\n",
    "GridSpace = SearchGrid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.17511289513296538\n",
      "ROC-AUC is: 0.5899148573319357\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "crossvalidate.setClassifier(classifier)\n",
    "crossvalidate.run()\n",
    "f1, roc = crossvalidate.getMetrics().getScores()\n",
    "print(f\"F1 score is: {f1}\")\n",
    "print(f\"ROC-AUC is: {roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, as with previous classifiers, we want to try adjusting the weights. Let's try balanced before moving onto to GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.1615720524017467\n",
      "ROC-AUC is: 0.5762615873157263\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "crossvalidate.setClassifier(classifier)\n",
    "crossvalidate.run()\n",
    "f1, roc = crossvalidate.getMetrics().getScores()\n",
    "print(f\"F1 score is: {f1}\")\n",
    "print(f\"ROC-AUC is: {roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GridSearch to find the best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.1771037181996086\n",
      "ROC-AUC is: 0.5932689032547743\n",
      "Best Parameters: {'class_weight': {0: 10, 1: 1}}\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "parameters = {'class_weight':[{0:1,1:1}, {0:1,1:10}, {0:1,1:100}, {0:10,1:1}]}\n",
    "GridSpace.setGridParameters(parameters)\n",
    "GridSpace.setClassifier(classifier)\n",
    "GridSpace.run()\n",
    "parameters, scores = GridSpace.getMetrics().getBestResults()\n",
    "f1 = scores[0]\n",
    "roc = scores[1]\n",
    "print(f\"F1 score is: {f1}\")\n",
    "print(f\"ROC-AUC is: {roc}\")\n",
    "print(f\"Best Parameters: {parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': {0: 1, 1: 1}} F1:  0.175 ROC_AUC:  0.59\n",
      "{'class_weight': {0: 1, 1: 10}} F1:  0.172 ROC_AUC:  0.586\n",
      "{'class_weight': {0: 1, 1: 100}} F1:  0.163 ROC_AUC:  0.577\n",
      "{'class_weight': {0: 10, 1: 1}} F1:  0.177 ROC_AUC:  0.593\n"
     ]
    }
   ],
   "source": [
    "params, scores = GridSpace.getMetrics().getAllresults()\n",
    "for i, j in zip(params, scores):\n",
    "    print(i, \"F1: \", round(j[0],3), \"ROC_AUC: \", round(j[1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are somewhat suprising, compared to our previous best weights (1:10 for nongilded to gilded). Let's try experimenting with the features next; we will keep both weights for comparison.\n",
    "\n",
    "We will also restrict the max_depth (to avoid overfitting and to limit the resources needed for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.264637366050629\n",
      "ROC-AUC is: 0.7197968100839228\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 10}, 'max_depth': 2, 'max_features': 6}\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "parameters = {'max_depth' : [2, 4],\n",
    "    'class_weight':[{0:1,1:10}, {0:10,1:1}], 'max_features' : [2, 4, 6]}\n",
    "GridSpace.setGridParameters(parameters)\n",
    "GridSpace.setClassifier(classifier)\n",
    "GridSpace.run()\n",
    "GridSpace.save(\"DTGrid01\") #Saving the grid as well, we can reuse it later\n",
    "parameters, scores = GridSpace.getMetrics().getBestResults()\n",
    "f1 = scores[0]\n",
    "roc = scores[1]\n",
    "print(f\"F1 score is: {f1}\")\n",
    "print(f\"ROC-AUC is: {roc}\")\n",
    "print(f\"Best Parameters: {parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Scores:\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 2, 'max_features': 2} F1:  0.244 ROC_AUC:  0.762\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 2, 'max_features': 4} F1:  0.247 ROC_AUC:  0.76\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 2, 'max_features': 6} F1:  0.265 ROC_AUC:  0.72\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 4, 'max_features': 2} F1:  0.22 ROC_AUC:  0.755\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 4, 'max_features': 4} F1:  0.25 ROC_AUC:  0.737\n",
      "{'class_weight': {0: 1, 1: 10}, 'max_depth': 4, 'max_features': 6} F1:  0.257 ROC_AUC:  0.727\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 2, 'max_features': 2} F1:  0.0 ROC_AUC:  0.5\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 2, 'max_features': 4} F1:  0.0 ROC_AUC:  0.5\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 2, 'max_features': 6} F1:  0.0 ROC_AUC:  0.5\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 4, 'max_features': 2} F1:  0.002 ROC_AUC:  0.501\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 4, 'max_features': 4} F1:  0.053 ROC_AUC:  0.514\n",
      "{'class_weight': {0: 10, 1: 1}, 'max_depth': 4, 'max_features': 6} F1:  0.053 ROC_AUC:  0.514\n"
     ]
    }
   ],
   "source": [
    "params, scores = GridSpace.getMetrics().getAllresults()\n",
    "print(\"\\nAll Scores:\")\n",
    "for i, j in zip(params, scores):\n",
    "    print(i, \"F1: \", round(j[0],3), \"ROC_AUC: \", round(j[1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like limiting the tree depth has produced results similar to our previous models. We can use graphviz to visualize the results (saved as tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "Data = DataStore()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4, class_weight={0:1, 1:10}, max_features=6)\n",
    "clf = clf.fit(Data.getxTrain(), Data.getyTrain())\n",
    "\n",
    "features_list=[\"comment_upvotes\", \"comment_karma\", \"link_karma\", \"is_premium\", \"comment_age\", \"edited_comment\"]\n",
    "tree.export_graphviz(clf, out_file='tree.dot', \n",
    "                     feature_names=features_list,  \n",
    "                      class_names=['Non gilded', 'gilded'],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)\n",
    "!dot -Tpng tree.dot -o tree.png #Convert dot file into png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our best parameters, we can evaluate the results on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.2881944444444445\n",
      "ROC_AUC score: 0.6718979759057488\n",
      "Balanced accuracy score: 0.671897975905749\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GridSpace = GridSpace.load(\"models/DTGrid01.pkl\")\n",
    "y_preds = GridSpace.grid.predict(Data.getxTest())\n",
    "print(f\"F1 score: {f1_score(Data.getyTest(), y_preds)}\")\n",
    "print(f\"ROC_AUC score: {roc_auc_score(Data.getyTest(), y_preds)}\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(Data.getyTest(), y_preds)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparable results to both SVM (0.29) and Logistic Regression (0.297), before sampling. Let's apply resampling techniques, train the model and then evaluate them on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sampling Data...\n"
     ]
    }
   ],
   "source": [
    "SampledDataStore = sds()\n",
    "SampledDataStore.initializeSamplers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random OverSampler on test set:\n",
      "F1 score: 0.03627962693591169\n",
      "ROC_AUC score: 0.8964295492796688\n",
      "Balanced accuracy score: 0.8964295492796688\n",
      "\n",
      "\n",
      "SMOTE on test set:\n",
      "F1 score: 0.04801623083859333\n",
      "ROC_AUC score: 0.9098513536910428\n",
      "Balanced accuracy score: 0.9098513536910428\n",
      "\n",
      "\n",
      "ADASYN on test set:\n",
      "F1 score: 0.03742166517457476\n",
      "ROC_AUC score: 0.8922491423670668\n",
      "Balanced accuracy score: 0.8922491423670669\n",
      "\n",
      "\n",
      "SMOTE TOMEK on test set:\n",
      "F1 score: 0.04928909952606635\n",
      "ROC_AUC score: 0.9011539793362808\n",
      "Balanced accuracy score: 0.9011539793362807\n",
      "\n",
      "\n",
      "SMOTE ENN on test set:\n",
      "F1 score: 0.058240946045824096\n",
      "ROC_AUC score: 0.8849373183066379\n",
      "Balanced accuracy score: 0.884937318306638\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random = SampledDataStore.getRandomSampled\n",
    "smote = SampledDataStore.getSMOTESampled\n",
    "ada = SampledDataStore.getADASYNSampled\n",
    "smote_tomek = SampledDataStore.getSMOTETOMEKSampled\n",
    "smote_enn = SampledDataStore.getSMOTEENNSampled\n",
    "samplers = [random, smote, ada, smote_tomek, smote_enn]\n",
    "sampler_names = [\"Random OverSampler\", \"SMOTE\", \"ADASYN\", \"SMOTE TOMEK\", \"SMOTE ENN\"]\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=4, max_features=4)\n",
    "\n",
    "for i in range(len(samplers)):\n",
    "    parameters = {'class_weight':[{0:1,1:10}]}\n",
    "    X_resampled, y_resampled = samplers[i]()\n",
    "    GridSpace.getDataStore().setxTrain(X_resampled)\n",
    "    GridSpace.getDataStore().setyTrain(y_resampled) \n",
    "    GridSpace.setGridParameters(parameters)\n",
    "    GridSpace.setClassifier(classifier)\n",
    "    grid = GridSpace.run()\n",
    "    GridSpace.save(f\"DT_{sampler_names[i]}\")\n",
    "    y_preds = grid.predict(GridSpace.getDataStore().getxTest())\n",
    "    print(f\"{sampler_names[i]} on test set:\")\n",
    "    print(f\"F1 score: {f1_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(f\"ROC_AUC score: {roc_auc_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(f\"Balanced accuracy score: {balanced_accuracy_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "GridSpace.getDataStore().revertToOriginal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random OverSampler on test set:\n",
      "F1 score: 0.04449623900836953\n",
      "ROC_AUC score: 0.9013062796447064\n",
      "Balanced accuracy score: 0.9013062796447064\n",
      "\n",
      "\n",
      "SMOTE on test set:\n",
      "F1 score: 0.04999396208187417\n",
      "ROC_AUC score: 0.899706824422809\n",
      "Balanced accuracy score: 0.899706824422809\n",
      "\n",
      "\n",
      "ADASYN on test set:\n",
      "F1 score: 0.049312470365101946\n",
      "ROC_AUC score: 0.9011700851190619\n",
      "Balanced accuracy score: 0.901170085119062\n",
      "\n",
      "\n",
      "SMOTE TOMEK on test set:\n",
      "F1 score: 0.05060211653083567\n",
      "ROC_AUC score: 0.9020357709435572\n",
      "Balanced accuracy score: 0.9020357709435574\n",
      "\n",
      "\n",
      "SMOTE ENN on test set:\n",
      "F1 score: 0.05144058365277607\n",
      "ROC_AUC score: 0.9025753146667311\n",
      "Balanced accuracy score: 0.9025753146667311\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random = SampledDataStore.getRandomSampled\n",
    "smote = SampledDataStore.getSMOTESampled\n",
    "ada = SampledDataStore.getADASYNSampled\n",
    "smote_tomek = SampledDataStore.getSMOTETOMEKSampled\n",
    "smote_enn = SampledDataStore.getSMOTEENNSampled\n",
    "samplers = [random, smote, ada, smote_tomek, smote_enn]\n",
    "sampler_names = [\"Random OverSampler\", \"SMOTE\", \"ADASYN\", \"SMOTE TOMEK\", \"SMOTE ENN\"]\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=4, max_features=6)\n",
    "\n",
    "for i in range(len(samplers)):\n",
    "    parameters = {'class_weight':[{0:1,1:10}]}\n",
    "    X_resampled, y_resampled = samplers[i]()\n",
    "    GridSpace.getDataStore().setxTrain(X_resampled)\n",
    "    GridSpace.getDataStore().setyTrain(y_resampled) \n",
    "    GridSpace.setGridParameters(parameters)\n",
    "    GridSpace.setClassifier(classifier)\n",
    "    grid = GridSpace.run()\n",
    "    GridSpace.save(f\"DT_{sampler_names[i]}\")\n",
    "    y_preds = grid.predict(GridSpace.getDataStore().getxTest())\n",
    "    print(f\"{sampler_names[i]} on test set:\")\n",
    "    print(f\"F1 score: {f1_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(f\"ROC_AUC score: {roc_auc_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(f\"Balanced accuracy score: {balanced_accuracy_score(GridSpace.getDataStore().getyTest(), y_preds)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "GridSpace.getDataStore().revertToOriginal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better results than with the original features set, but still worse when compared to SVM or Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
