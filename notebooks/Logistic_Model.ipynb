{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/processed/train_data_baseline.csv\")\n",
    "test_data = pd.read_csv(\"../data/processed/test_data_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class filter_add_attributes(BaseEstimator, TransformerMixin):\n",
    "    '''Custom transformer based on Sklearn's classes.\n",
    "    Takes in dataframe (train or test) and adds new features and returns\n",
    "    a filtered version of the original train/test datasets.'''\n",
    "    def fit(self, X, y=None):\n",
    "        return self.fit_transform(X)\n",
    "    def transform(self, X, y=None):\n",
    "        return self.fit_transform(X)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        '''Calculates and adds comment body length and account activity (based on frequency of comment author)\n",
    "        as features. Returns a new dataframe with the added columns.'''\n",
    "        data = X.copy()\n",
    "        data[\"body_len\"] = data.comment_body.apply(lambda x: len(x))\n",
    "        data[\"acc_activity\"] = data.author_ids.map(data.author_ids.value_counts())\n",
    "        data[\"is_premium\"] = data.is_premium.astype(int)\n",
    "        return data.filter(items=[\"ups\", \"comment_karma\", \"link_karma\", \"is_premium\", \"comment_age_days\", \"acc_age_days\", \"body_len\", \"acc_activity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('filter_add', filter_add_attributes()),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_train = pipeline.fit_transform(train_data)\n",
    "X_test = pipeline.transform(test_data)\n",
    "y_train = train_data[\"gildings\"].to_list()\n",
    "y_test = test_data[\"gildings\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.14332273886338903\n",
      "ROC-AUC is: 0.8478763439152004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "def train_eval(clf, X, y):\n",
    "    '''Takes in train and train datasets along a model to train and evaluate. Returns f1 and roc-auc scores.'''\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "    scores = cross_validate(clf, X, y, cv=rskf, scoring=['f1', 'roc_auc'])\n",
    "    return scores['test_f1'], scores['test_roc_auc']\n",
    "\n",
    "clf = LogisticRegression()\n",
    "f1, roc = train_eval(clf, X_train, y_train)\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    510995\n",
      "1       995\n",
      "Name: gildings, dtype: int64\n",
      "0    127749\n",
      "1       249\n",
      "Name: gildings, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.gildings.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high class imbalance, F1 score is a much better metric to use than just accuracy (since 99% of the data belongs to class 0). We will also have ROC-AUC for comparison.\n",
    "\n",
    "The low score is to expected. Let's try using the class weight functionality in Sklearn that assigns weights to each class based on their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.0734904371963277\n",
      "ROC-AUC is: 0.9119952192683487\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced')\n",
    "f1, roc = train_eval(clf, X_train, y_train)\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced class weight results in a worse f1 score; let's try with bunch of different weight values. We will use F1 score for refitting (finding the best parameters) as ROC-AUC seems to be too optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.12137251216239651\n",
      "ROC-AUC is: 0.8801967569473819\n",
      "Best class weights: {'class_weight': {0: 1, 1: 10}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_eval_weights(X_train, y_train):\n",
    "    '''Function to train and evalute Logistic Regression (w/ Cross Validation) Model.'''\n",
    "    model = LogisticRegression()\n",
    "    parameters = {'class_weight':[{0:1,1:1}, {0:1,1:10}, {0:1,1:100}, {0:1,1:1000}, {0:1,1:10000}, {0:10,1:1}]}\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "    clf = GridSearchCV(model, parameters, scoring=['f1', 'roc_auc'], cv=rskf, refit='f1')\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.cv_results_['mean_test_f1'], clf.cv_results_['mean_test_roc_auc'], clf.best_params_\n",
    "\n",
    "f1, roc, best = train_eval_weights(X_train, y_train)\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")\n",
    "print(f\"Best class weights: {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making progress, but can we do even better?\n",
    "\n",
    "Adjusting the weights were not enough, we will have to try different sampling techniques. We can use imbalanced-learn library for this. Let's start with oversampling class 1 (gilded) with SMOTE and ADASYN techniques with a 0.1 ratio (~10% increase in gilded class).\n",
    "\n",
    "Read more: https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#a-practical-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smote - F1 score is: 0.6097897316663436\n",
      "Smote - ROC-AUC is: 0.8961593223446982\n",
      "ADASYN - F1 score is: 0.557028301538202\n",
      "ADASYN - ROC-AUC is: 0.8835737972917235\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "#Using SMOTE to generate samples in gilded class\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(f\"Smote - F1 score is: {np.mean(f1)}\")\n",
    "print(f\"Smote - ROC-AUC is: {np.mean(roc)}\")\n",
    "\n",
    "#Using ADASYN to generate samples in gilded class\n",
    "\n",
    "ada = ADASYN(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = ada.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(f\"ADASYN - F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ADASYN - ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Programming-Files",
   "language": "python",
   "name": "programming-files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
