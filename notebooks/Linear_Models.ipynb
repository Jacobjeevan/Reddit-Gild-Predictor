{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/processed/train_data_baseline.csv\")\n",
    "test_data = pd.read_csv(\"../data/processed/test_data_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class filter_add_attributes(BaseEstimator, TransformerMixin):\n",
    "    '''Custom transformer based on Sklearn's classes.\n",
    "    Takes in dataframe (train or test) and adds new features and returns\n",
    "    a filtered version of the original train/test datasets.'''\n",
    "    def fit(self, X, y=None):\n",
    "        return self.fit_transform(X)\n",
    "    def transform(self, X, y=None):\n",
    "        return self.fit_transform(X)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        '''Calculates and adds comment body length and account activity (based on frequency of comment author)\n",
    "        as features. Returns a new dataframe with the added columns.'''\n",
    "        data = X.copy()\n",
    "        data[\"body_len\"] = data.comment_body.apply(lambda x: len(x))\n",
    "        data[\"acc_activity\"] = data.author_ids.map(data.author_ids.value_counts())\n",
    "        data[\"is_premium\"] = data.is_premium.astype(int)\n",
    "        return data.filter(items=[\"ups\", \"comment_karma\", \"link_karma\", \"is_premium\", \"comment_age_days\", \"acc_age_days\", \"body_len\", \"acc_activity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('filter_add', filter_add_attributes()),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_train = pipeline.fit_transform(train_data)\n",
    "X_test = pipeline.transform(test_data)\n",
    "y_train = train_data[\"gildings\"].to_list()\n",
    "y_test = test_data[\"gildings\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's establish a baseline model where classifer simply predicts the minority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.003879255539090453\n",
      "ROC-AUC is: 0.5\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "scores = cross_validate(clf, X_train, y_train, cv=rskf, scoring=['f1', 'roc_auc']) \n",
    "f1, roc = scores['test_f1'], scores['test_roc_auc']\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good model is one that can perform better than the baseline, in terms of F1 Score. Anything below is worse than a model that simply predicts minority class.\n",
    "\n",
    "Note that 0.5 ROC-AUC score indicates that it's a random classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(clf, X, y):\n",
    "    '''Takes in train and train datasets along a model to train and evaluate. Returns f1 and roc-auc scores.'''\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "    scores = cross_validate(clf, X, y, cv=rskf, scoring=['f1', 'roc_auc'])\n",
    "    return scores['test_f1'], scores['test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.14332273886338903\n",
      "ROC-AUC is: 0.8478763439152004\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "f1, roc = train_eval(clf, X_train, y_train)\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    510995\n",
      "1       995\n",
      "Name: gildings, dtype: int64\n",
      "0    127749\n",
      "1       249\n",
      "Name: gildings, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.gildings.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high class imbalance, F1 score is a much better metric to use than just accuracy (since 99% of the data belongs to class 0). We will also have ROC-AUC for comparison.\n",
    "\n",
    "The low score is to expected. Let's try using the class weight functionality in Sklearn that assigns weights to each class based on their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.0734904371963277\n",
      "ROC-AUC is: 0.9119952192683487\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced')\n",
    "f1, roc = train_eval(clf, X_train, y_train)\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced class weight results in a worse f1 score; let's try with bunch of different weight values. We will use F1 score for refitting (finding the best parameters) as ROC-AUC seems to be too optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is: 0.12137251216239651\n",
      "ROC-AUC is: 0.8801967569473819\n",
      "Best class weights: {'class_weight': {0: 1, 1: 10}}\n"
     ]
    }
   ],
   "source": [
    "def train_eval_weights(X_train, y_train, parameters):\n",
    "    '''Function to train and evalute Logistic Regression (w/ Cross Validation) Model.'''\n",
    "    model = LogisticRegression()\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "    clf = GridSearchCV(model, parameters, scoring=['f1', 'roc_auc'], cv=rskf, refit='f1')\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "parameters = {'class_weight':[{0:1,1:1}, {0:1,1:10}, {0:1,1:100}, {0:1,1:1000}, {0:1,1:10000}, {0:10,1:1}]}\n",
    "clf = train_eval_weights(X_train, y_train, parameters)\n",
    "f1, roc, best =  clf.cv_results_['mean_test_f1'], clf.cv_results_['mean_test_roc_auc'], clf.best_params_\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")\n",
    "print(f\"Best class weights: {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making progress, but can we do even better?\n",
    "\n",
    "Adjusting the weights were not enough, we will have to try different sampling techniques. Imbalanced-learn library will come in handy here.\n",
    "\n",
    "We will start with RandomOverSampler to duplicates records from the minority class. We will use a sampling ratio of 0.1 (i.e. ~10% increase in gilded class).\n",
    "\n",
    "Read more: https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#a-practical-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over Sampling:\n",
      "F1 score is: 0.6137350074209578\n",
      "ROC-AUC is: 0.8983875798873713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using RandomOverSampler to duplicate records belonging to class 1 (gilded)\n",
    "\n",
    "random_sampler = RandomOverSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = random_sampler.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight={0: 1, 1: 10})\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(\"Random Over Sampling:\")\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate new samples with SMOTE and ADASYN based on existing samples. We will keep the sampling ratio the same for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smote - F1 score is: 0.6097897316663436\n",
      "Smote - ROC-AUC is: 0.8961593223446982\n",
      "ADASYN - F1 score is: 0.557028301538202\n",
      "ADASYN - ROC-AUC is: 0.8835737972917235\n"
     ]
    }
   ],
   "source": [
    "#Using SMOTE to generate samples in gilded class\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(\"SMOTE:\")\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\\n\")\n",
    "\n",
    "#Using ADASYN to generate samples in gilded class\n",
    "\n",
    "ada = ADASYN(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = ada.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(\"ADASYN:\")\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced learn also recommends combining oversampling with undersampling the majority class.\n",
    "\n",
    "Ref: https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
    "\n",
    "SMOTE can generate noisy samples (ex: when classes cannot be well separated), undersampling allows to clean the noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE - Tomek's Link:\n",
      "F1 score is: 0.6117476376281973\n",
      "ROC-AUC is: 0.8968529733151215\n",
      "\n",
      "SMOTE - Edited nearest neighbours:\n",
      "F1 score is: 0.700327337392521\n",
      "ROC-AUC is: 0.9207147669601824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_tomek = SMOTETomek(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(\"SMOTE - Tomek's Link:\")\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\\n\")\n",
    "\n",
    "smote_enn = SMOTEENN(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "clf = LogisticRegression(class_weight=[{0: 1, 1: 10}])\n",
    "f1, roc = train_eval(clf, X_resampled, y_resampled)\n",
    "print(\"SMOTE - Edited nearest neighbours:\")\n",
    "print(f\"F1 score is: {np.mean(f1)}\")\n",
    "print(f\"ROC-AUC is: {np.mean(roc)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTEENN and RandomOverSampler produces the best results so far.\n",
    "\n",
    "Logistic regression predicts the class probabilities for each sample and decides class based on a threshold (default: 0.5). We can evaluate SMOTEENN and RandomOverSampler on our test set and check if a different threshold value produces better results.\n",
    "\n",
    "Ref: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over Sampling:\n",
      "\n",
      "Maxiziming F1 Score:\n",
      "Threshold: 0.9470000000000001, F1 Score: 0.3143350604490501, ROC AUC: 0.681795495628806\n",
      "Maxiziming ROC-AUC Score:\n",
      "Threshold: 0.114, F1 Score: 0.06988058381247236, ROC AUC: 0.8011632750856418\n"
     ]
    }
   ],
   "source": [
    "def train_eval_probs(X, y, X_test):\n",
    "    '''Takes in train and train datasets along a model to train and evaluate. Returns f1 and roc-auc scores.'''\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "    model = LogisticRegressionCV(cv=rskf, class_weight=[{0: 1, 1: 10}])\n",
    "    model.fit(X, y)\n",
    "    return model.predict_proba(X_test)[:,1]\n",
    "\n",
    "def convert_probs(probs, threshold):\n",
    "    return (probs >= threshold).astype('int')\n",
    "\n",
    "random_sampler = RandomOverSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = random_sampler.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "probs = train_eval_probs(X_resampled, y_resampled, X_test)\n",
    "\n",
    "thresholds = np.arange(0, 1, 0.001)\n",
    "f1_scores = [f1_score(y_test, convert_probs(probs, t)) for t in thresholds]\n",
    "auc_scores = [roc_auc_score(y_test, convert_probs(probs, t)) for t in thresholds]\n",
    "ind1 = np.argmax(f1_scores)\n",
    "ind2 = np.argmax(auc_scores)\n",
    "\n",
    "print(\"Random Over Sampling:\\n\")\n",
    "print(\"Maxiziming F1 Score:\")\n",
    "print(f\"Threshold: {thresholds[ind1]}, F1 Score: {f1_scores[ind1]}, ROC AUC: {auc_scores[ind1]}\")\n",
    "print(\"Maxiziming ROC-AUC Score:\")\n",
    "print(f\"Threshold: {thresholds[ind2]}, F1 Score: {f1_scores[ind2]}, ROC AUC: {auc_scores[ind2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE - Edited nearest neighbours:\n",
      "\n",
      "Maxiziming F1 Score:\n",
      "Threshold: 0.998, F1 Score: 0.3019431988041854, ROC AUC: 0.7015627029169681\n",
      "Maxiziming ROC-AUC Score:\n",
      "Threshold: 0.107, F1 Score: 0.08415217939027463, ROC AUC: 0.8214351900710419\n"
     ]
    }
   ],
   "source": [
    "smote_enn = SMOTEENN(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "assert len(X_resampled) == len(y_resampled)\n",
    "probs = train_eval_probs(X_resampled, y_resampled, X_test)\n",
    "\n",
    "f1_scores = [f1_score(y_test, convert_probs(probs, t)) for t in thresholds]\n",
    "auc_scores = [roc_auc_score(y_test, convert_probs(probs, t)) for t in thresholds]\n",
    "ind1 = np.argmax(f1_scores)\n",
    "ind2 = np.argmax(auc_scores)\n",
    "\n",
    "print(\"SMOTE - Edited nearest neighbours:\\n\")\n",
    "print(\"Maxiziming F1 Score:\")\n",
    "print(f\"Threshold: {thresholds[ind1]}, F1 Score: {f1_scores[ind1]}, ROC AUC: {auc_scores[ind1]}\")\n",
    "print(\"Maxiziming ROC-AUC Score:\")\n",
    "print(f\"Threshold: {thresholds[ind2]}, F1 Score: {f1_scores[ind2]}, ROC AUC: {auc_scores[ind2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Oversampling on test set:\n",
      "F1 score: 0.0638904734740445\n",
      "ROC_AUC score: 0.8183981729232407\n",
      "Accuracy score: 0.9615384615384616\n",
      "\n",
      "\n",
      "SMOTE on test set:\n",
      "F1 score: 0.060296191819464044\n",
      "ROC_AUC score: 0.8228175600742684\n",
      "Accuracy score: 0.9583587243550681\n",
      "\n",
      "\n",
      "SMOTE ENN on test set:\n",
      "F1 score: 0.08897775556110973\n",
      "ROC_AUC score: 0.8434413510604898\n",
      "Accuracy score: 0.9715229925467586\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_sampler = RandomOverSampler(sampling_strategy=0.1, random_state=42)\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "smote_enn = SMOTEENN(sampling_strategy=0.1, random_state=42)\n",
    "models = [random_sampler, smote, smote_enn]\n",
    "model_names = [\"Random Oversampling\", \"SMOTE\", \"SMOTE ENN\"]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    parameters = {'class_weight':[{0:1,1:10}]}\n",
    "    X_resampled, y_resampled = models[i].fit_resample(X_train, y_train)\n",
    "    grid_res = train_eval_weights(X_resampled, y_resampled, parameters)\n",
    "    y_preds = grid_res.predict(X_test)\n",
    "    print(f\"{model_names[i]} on test set:\")\n",
    "    print(f\"F1 score: {f1_score(y_test, y_preds)}\")\n",
    "    print(f\"ROC_AUC score: {roc_auc_score(y_test, y_preds)}\")\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_preds)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than our baseline model, but still not good enough. We will have to experiment with a more complex model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Programming-Files",
   "language": "python",
   "name": "programming-files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
